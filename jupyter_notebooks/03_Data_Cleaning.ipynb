{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Evaluate missing data\n",
        "- Clean data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- outputs/datasets/collection/house_prices_records.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Cleaned Train and Test sets\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "metadata": {},
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "metadata": {},
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "metadata": {},
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\")\n",
        "    )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide the threshold for the heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Predictive power Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
        "                  df_corr_spearman=df_corr_spearman, \n",
        "                  pps_matrix=pps_matrix,\n",
        "                  CorrThreshold=0.4, PPS_Threshold=0.15,\n",
        "                  figsize=(10,10), font_annot=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "  missing_data_absolute = df.isnull().sum()\n",
        "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
        "  df_missing_data = (pd.DataFrame(\n",
        "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                 \"DataType\":df.dtypes}\n",
        "                                  )\n",
        "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a copy first and apply the changes individually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned = df.copy()\n",
        "df_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order of appearance:\n",
        "\n",
        "- EnclosedPorch - 90.68% missing data:\n",
        "We drop this\n",
        "\n",
        "- WooDeckSF - 89.38% missing data:\n",
        "We drop this\n",
        "\n",
        "- LotFrontage - 17.74% missing data:\n",
        "    - Moderate correlation to Sale Price, no predicting power\n",
        "    - Missing data cannot be 0, as logically as it represents linear feet of street connected to the property.\n",
        "    - Significant right skew\n",
        "    - Might use the median to fill the missing data\n",
        "    - median = 69\n",
        "    - mean = 70\n",
        "\n",
        "- GarageFinish - 11.10% missing data:\n",
        "    - Categorical\n",
        "    - 4 values: unf, rfn, fin, none\n",
        "    - check if null and none have no garage area, if no garage area we can impute none, otherwise unf\n",
        "\n",
        "- BsmtFinType1 - 7.81% missing data:\n",
        "    - 7 categorical text values\n",
        "    - like with garage, check missing values if they have basement area\n",
        "\n",
        "- BedroomAbvGr - 6.78% missing data:\n",
        "    - further analysis required\n",
        "    - median = 3\n",
        "    - mean = 2.9\n",
        "\n",
        "- 2ndFlrSF - 5.89% missing data:\n",
        "    - If no second floor, value can be set to 0\n",
        "    - Needs comparing with other properties\n",
        "\n",
        "- GarageYrBlt - 5.55% missing data:\n",
        "    - very high correlation with year built\n",
        "    - missing data could be built year data, logically makes sense\n",
        "    - if garagefinish, area and yearbuilt is none property could have no garage\n",
        "\n",
        "- MasVnrArea - 0.55% missing data:\n",
        "    - lack of value could mean no masonry veneer area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EnclosedPorch and WooDeckSF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Significant amount of data missing. We drop these variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned = df_cleaned.drop(columns=['EnclosedPorch', 'WoodDeckSF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check that the variables have been correcty dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "for column in df_cleaned.columns:\n",
        "    print(column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LotFrontage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_lotfrontage = df_cleaned[df_cleaned['LotFrontage'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_lotfrontage)}\")\n",
        "missing_lotfrontage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculate the median value of 'LotFrontage' from the cleaned data\n",
        "median_lot_frontage = df_cleaned['LotFrontage'].median()\n",
        "print(f\"Median value is: {median_lot_frontage}\")\n",
        "\n",
        "# Fill missing values in 'LotFrontage' with the median\n",
        "df_cleaned['LotFrontage'].fillna(median_lot_frontage, inplace=True)\n",
        "print(\"Filled the missing data with the median value\")\n",
        "\n",
        "# Verify the changes by checking for any remaining null values in the 'LotFrontage' column\n",
        "print(f\"Variables with missing Lot Frontage value: {len(missing_lotfrontage)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GarageFinish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_garage_finish = df_cleaned[df_cleaned['GarageFinish'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_garage_finish)}\")\n",
        "missing_garage_finish[['GarageFinish', 'GarageYrBlt', 'GarageArea']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we check garareArea, if it is 0, we apply \"None\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_no_garage_area = df_cleaned[(df_cleaned['GarageFinish'].isnull()) & (df['GarageArea'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_no_garage_area)}\")\n",
        "df_no_garage_area[['GarageFinish', 'GarageYrBlt', 'GarageArea']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "initial_count = df_cleaned[(df_cleaned['GarageArea'] == 0) & (df_cleaned['GarageFinish'].isnull())].shape[0]\n",
        "print(f\"Initial number of rows with 'GarageFinish' missing and no 'GarageArea' value: {initial_count}\")\n",
        "\n",
        "df_cleaned.loc[(df_cleaned['GarageArea'] == 0) & (df_cleaned['GarageFinish'].isnull()), 'GarageFinish'] = 'None'\n",
        "\n",
        "remaining_count = df_cleaned[(df_cleaned['GarageArea'] == 0) & (df_cleaned['GarageFinish'].isnull())].shape[0]\n",
        "print(f\"Remaining number of rows with 'GarageFinish' missing and no 'GarageArea' value after update: {remaining_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the rest of the missing values have a GarageArea, we will impute \"Unf\" as it is the most common value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "initial_count = df_cleaned[(df_cleaned['GarageFinish'].isnull())].shape[0]\n",
        "print(f\"Initial number of rows with 'GarageFinish' missing: {initial_count}\")\n",
        "\n",
        "df_cleaned.loc[(df_cleaned['GarageFinish'].isnull()), 'GarageFinish'] = 'Unf'\n",
        "print(f\"Remaining missing 'GarageFinish' entries: {df_cleaned['GarageFinish'].isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BsmtFinType1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for BsmtFinType1 missing values and TotalBsmtSF value of 0.\n",
        "These values will have no basement and thus BsmtFinType1 will be none.\n",
        "The rows below have no finished, unfinished and total basement, furthermore also no BsmtExposure, we can safely say there is no basement and impute None."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_basement_none = df_cleaned[(df['BsmtFinType1'].isnull()) & (df['TotalBsmtSF'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_none)}\")\n",
        "df_basement_none[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1', 'BsmtExposure']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us apply the changes to the copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.loc[(df_cleaned['TotalBsmtSF'] == 0) & (df_cleaned['BsmtFinType1'].isnull()), 'BsmtFinType1'] = 'None'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The values belows indicate that the variable BsmtUnfSF has 0 square feet unfinished, and since the TotalBsmtSF is greater than 0, it suggests the basement is finished but no category has been assigned.\n",
        "As we cannot deduce if it is a rec room/living quarter and the quality, we should create a new category: \"Finished\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_basement_finished = df_cleaned[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_finished)}\")\n",
        "df_basement_finished[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us apply the changes to the copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.loc[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] == 0), 'BsmtFinType1'] = 'Fin'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The values below have a value of unfinished SF basement higher than 0. We can impute \"Unfinished\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_basement_unfinished = df_cleaned[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] > 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_unfinished)}\")\n",
        "df_basement_unfinished[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.loc[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] > 0), 'BsmtFinType1'] = 'Unf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BedroomAbvGr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bedroom_abv_gr = df_cleaned[df_cleaned['BedroomAbvGr'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bedroom_abv_gr)}\")\n",
        "missing_bedroom_abv_gr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Median input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculate the median value of 'BedroomAbvGr' from the cleaned data\n",
        "median_bedroom_abv_gr = df_cleaned['BedroomAbvGr'].median()\n",
        "\n",
        "# Impute missing values with the calculated median\n",
        "df_cleaned['BedroomAbvGr'].fillna(median_bedroom_abv_gr, inplace=True)\n",
        "\n",
        "# Print the median value used for imputation\n",
        "print(f\"Median number of bedrooms above grade used for imputation: {median_bedroom_abv_gr}\")\n",
        "\n",
        "# Re-check and print the amount of missing data in 'BedroomAbvGr' to ensure no missing values remain\n",
        "missing_after_imputation = df_cleaned['BedroomAbvGr'].isnull().sum()\n",
        "print(f\"Amount of rows with missing 'BedroomAbvGr' data after imputation: {missing_after_imputation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2ndFlrSF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_2nd_flr_sf = df_cleaned[df_cleaned['2ndFlrSF'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_2nd_flr_sf)}\")\n",
        "missing_2nd_flr_sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Print the number of missing entries before imputation\n",
        "initial_missing = df_cleaned['2ndFlrSF'].isnull().sum()\n",
        "print(f\"Amount of rows with missing '2ndFlrSF' data before imputation: {initial_missing}\")\n",
        "\n",
        "# Impute 0 for all missing values in '2ndFlrSF'\n",
        "df_cleaned['2ndFlrSF'].fillna(0, inplace=True)\n",
        "\n",
        "# Check and print the amount of missing data in '2ndFlrSF' after imputation to ensure no missing values remain\n",
        "final_missing = df_cleaned['2ndFlrSF'].isnull().sum()\n",
        "print(f\"Amount of rows with missing '2ndFlrSF' data after imputation: {final_missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GarageYrBlt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_garage_yr_built = df_cleaned[df_cleaned['GarageYrBlt'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_garage_yr_built)}\")\n",
        "missing_garage_yr_built[['GarageYrBlt', 'GarageFinish', 'GarageArea', 'YearBuilt', 'YearRemodAdd']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check GarageYrBlt and GarageArea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_garage_year_none = df_cleaned[(df_cleaned['GarageYrBlt'].isnull()) & (df_cleaned['GarageArea'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_garage_year_none)}\")\n",
        "df_garage_year_none[['GarageYrBlt', 'GarageFinish', 'GarageArea', 'YearBuilt', 'YearRemodAdd']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All missing values in GarageYrBlt correspond to properties without a garage, as indicated by a zero in the GarageArea.\n",
        "\n",
        "The GarageYrBlt variable has significant Power Predictive Scores (PPS) of 0.6 with YearBuilt and 0.4 with YearRemodAdd, strongly suggesting that garages are typically constructed at the same time as the main house or during major renovations. This substantial overlap implies that GarageYrBlt does not add unique value beyond what is already conveyed by YearBuilt or YearRemodelAdd.\n",
        "\n",
        "Considering this redundancy, although we could impute a value of 0 for properties without garages to indicate no garage was built, it's more prudent to remove GarageYrBlt from the dataset entirely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.drop('GarageYrBlt', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "for column in df_cleaned.columns:\n",
        "    print(column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MasVnrArea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_mas_vnr_area = df_cleaned[df_cleaned['MasVnrArea'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_mas_vnr_area)}\")\n",
        "missing_mas_vnr_area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The missing values for the 'MasVnrArea' variable will be filled with zero, which is its median value. Imputing zero is meaningful in this context, as it indicates properties that do not have any masonry veneer area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned['MasVnrArea'].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_mas_vnr_area = df_cleaned[df_cleaned['MasVnrArea'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_mas_vnr_area)}\")\n",
        "missing_mas_vnr_area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=['number']).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue='Type', data=dfAux, x=\"Value\",palette=['#432371',\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# List of variables that we want to analyze to see the effect of data cleaning\n",
        "variables_to_analyze = [\n",
        "    'GarageFinish', 'LotFrontage', \n",
        "    'BsmtFinType1', 'BedroomAbvGr', '2ndFlrSF', 'MasVnrArea'\n",
        "]\n",
        "\n",
        "# 'df_original' refers to the DataFrame before any cleaning was applied\n",
        "# 'df_cleaned' refers to the DataFrame after cleaning operations have been performed\n",
        "# 'variables_applied_with_method' is a list of variable names that we want to compare\n",
        "# This function will display visual comparisons for each variable listed\n",
        "DataCleaningEffect(df_original=df, df_cleaned=df_cleaned, variables_applied_with_method=variables_to_analyze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculate the number of missing values per column\n",
        "missing_counts = df_cleaned.isnull().sum()\n",
        "\n",
        "# Filter out columns that have missing values\n",
        "missing_columns = missing_counts[missing_counts > 0]\n",
        "\n",
        "# Check if there are any columns with missing data and print the results\n",
        "if not missing_columns.empty:\n",
        "    print(f\"There are {len(missing_columns)} variables with missing data:\")\n",
        "    print(missing_columns)\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "metadata": {},
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
