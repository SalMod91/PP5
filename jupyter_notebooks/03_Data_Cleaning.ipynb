{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Evaluate missing data\n",
        "- Clean data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- outputs/datasets/collection/house_prices_records.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Cleaned Train and Test sets\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "metadata": {},
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "metadata": {},
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "metadata": {},
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\")\n",
        "    )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide the threshold for the heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Predictive power Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
        "                  df_corr_spearman=df_corr_spearman, \n",
        "                  pps_matrix=pps_matrix,\n",
        "                  CorrThreshold=0.4, PPS_Threshold=0.15,\n",
        "                  figsize=(10,10), font_annot=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "  missing_data_absolute = df.isnull().sum()\n",
        "  missing_data_percentage = round(missing_data_absolute/len(df)*100 , 2)\n",
        "  df_missing_data = (pd.DataFrame(\n",
        "                          data= {\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                 \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                 \"DataType\":df.dtypes}\n",
        "                                  )\n",
        "                    .sort_values(by=['PercentageOfDataset'],ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a copy first and apply the changes individually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned = df.copy()\n",
        "df_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order of appearance:\n",
        "\n",
        "- EnclosedPorch - 90.68% missing data:\n",
        "We drop this\n",
        "\n",
        "- WooDeckSF - 89.38% missing data:\n",
        "We drop this\n",
        "\n",
        "- LotFrontage - 17.74% missing data:\n",
        "    - Moderate correlation to Sale Price, no predicting power\n",
        "    - Missing data cannot be 0, as logically as it represents linear feet of street connected to the property.\n",
        "    - Significant right skew\n",
        "    - Might use the median to fill the missing data\n",
        "    - median = 69\n",
        "    - mean = 70\n",
        "\n",
        "- GarageFinish - 11.10% missing data:\n",
        "    - Categorical\n",
        "    - 4 values: unf, rfn, fin, none\n",
        "    - check if null and none have no garage area, if no garage area we can impute none, otherwise unf\n",
        "\n",
        "- BsmtFinType1 - 7.81% missing data:\n",
        "    - 7 categorical text values\n",
        "    - like with garage, check missing values if they have basement area\n",
        "\n",
        "- BedroomAbvGr - 6.78% missing data:\n",
        "    - further analysis required\n",
        "    - median = 3\n",
        "    - mean = 2.9\n",
        "\n",
        "- 2ndFlrSF - 5.89% missing data:\n",
        "    - If no second floor, value can be set to 0\n",
        "    - Needs comparing with other properties\n",
        "\n",
        "- GarageYrBlt - 5.55% missing data:\n",
        "    - very high correlation with year built\n",
        "    - missing data could be built year data, logically makes sense\n",
        "    - if garagefinish, area and yearbuilt is none property could have no garage\n",
        "\n",
        "- MasVnrArea - 0.55% missing data:\n",
        "    - lack of value could mean no masonry veneer area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EnclosedPorch and WooDeckSF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Significant amount of data missing. We drop these variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned = df_cleaned.drop(columns=['EnclosedPorch', 'WoodDeckSF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check that the variables have been correcty dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "for column in df_cleaned.columns:\n",
        "    print(column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LotFrontage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_lotfrontage = df_cleaned[df_cleaned['LotFrontage'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_lotfrontage)}\")\n",
        "missing_lotfrontage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculate the median value of 'LotFrontage' from the cleaned data\n",
        "median_lot_frontage = df_cleaned['LotFrontage'].median()\n",
        "print(f\"Median value is: {median_lot_frontage}\")\n",
        "\n",
        "# Fill missing values in 'LotFrontage' with the median\n",
        "df_cleaned['LotFrontage'].fillna(median_lot_frontage, inplace=True)\n",
        "print(\"Filled the missing data with the median value\")\n",
        "\n",
        "# Verify the changes by checking for any remaining null values in the 'LotFrontage' column\n",
        "print(f\"Variables with missing Lot Frontage value: {len(missing_lotfrontage)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GarageFinish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_garage_finish = df_cleaned[df_cleaned['GarageFinish'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_garage_finish)}\")\n",
        "missing_garage_finish[['GarageFinish', 'GarageYrBlt', 'GarageArea']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we check garareArea, if it is 0, we apply \"None\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_no_garage_area = df_cleaned[(df_cleaned['GarageFinish'].isnull()) & (df['GarageArea'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_no_garage_area)}\")\n",
        "df_no_garage_area[['GarageFinish', 'GarageYrBlt', 'GarageArea']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "initial_count = df_cleaned[(df_cleaned['GarageArea'] == 0) & (df_cleaned['GarageFinish'].isnull())].shape[0]\n",
        "print(f\"Initial number of rows with 'GarageFinish' missing and no 'GarageArea' value: {initial_count}\")\n",
        "\n",
        "df_cleaned.loc[(df_cleaned['GarageArea'] == 0) & (df_cleaned['GarageFinish'].isnull()), 'GarageFinish'] = 'None'\n",
        "\n",
        "remaining_count = df_cleaned[(df_cleaned['GarageArea'] == 0) & (df_cleaned['GarageFinish'].isnull())].shape[0]\n",
        "print(f\"Remaining number of rows with 'GarageFinish' missing and no 'GarageArea' value after update: {remaining_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As the rest of the missing values have a GarageArea, we will impute \"Unf\" as it is the most common value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "initial_count = df_cleaned[(df_cleaned['GarageFinish'].isnull())].shape[0]\n",
        "print(f\"Initial number of rows with 'GarageFinish' missing: {initial_count}\")\n",
        "\n",
        "df_cleaned.loc[(df_cleaned['GarageFinish'].isnull()), 'GarageFinish'] = 'Unf'\n",
        "print(f\"Remaining missing 'GarageFinish' entries: {df_cleaned['GarageFinish'].isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BsmtFinType1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for BsmtFinType1 missing values and TotalBsmtSF value of 0.\n",
        "These values will have no basement and thus BsmtFinType1 will be none.\n",
        "The rows below have no finished, unfinished and total basement, furthermore also no BsmtExposure, we can safely say there is no basement and impute None."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_basement_none = df_cleaned[(df['BsmtFinType1'].isnull()) & (df['TotalBsmtSF'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_none)}\")\n",
        "df_basement_none[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1', 'BsmtExposure']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us apply the changes to the copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.loc[(df_cleaned['TotalBsmtSF'] == 0) & (df_cleaned['BsmtFinType1'].isnull()), 'BsmtFinType1'] = 'None'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The values belows indicate that the variable BsmtUnfSF has 0 square feet unfinished, and since the TotalBsmtSF is greater than 0, it suggests the basement is finished but no category has been assigned.\n",
        "As we cannot deduce if it is a rec room/living quarter and the quality, we should create a new category: \"Finished\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_basement_finished = df_cleaned[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_finished)}\")\n",
        "df_basement_finished[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us apply the changes to the copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.loc[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] == 0), 'BsmtFinType1'] = 'Fin'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The values below have a value of unfinished SF basement higher than 0. We can impute \"Unfinished\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_basement_unfinished = df_cleaned[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] > 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_unfinished)}\")\n",
        "df_basement_unfinished[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned.loc[(df_cleaned['BsmtFinType1'].isnull()) & (df['BsmtUnfSF'] > 0), 'BsmtFinType1'] = 'Unf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned['BsmtFinType1'].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[['BsmtFinType1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF1']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BedroomAbvGr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2ndFlrSF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GarageYrBlt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MasVnrArea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "metadata": {},
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
