{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Assess and quantify missing data.\n",
        "- Perform data cleaning to prepare for analysis and modeling.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- **Dataset**: outputs/datasets/collection/house_prices_records.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Cleaned datasets ready for training and testing models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "metadata": {},
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "metadata": {},
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "metadata": {},
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\")\n",
        "    )\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Profile Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will explore the dataset for missing values. The code below will analyze the distribution and shape of a variable with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we\"ve isolated the variable with missing data, let's generate a profile report to further investigate the characteristics of this missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will conduct another round of correlation and Power Predictive Score (PPS) analysis to further explore and understand the relationships between the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap=\"viridis\", annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap=\"rocket_r\", annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor=\"grey\")\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter([\"x\", \"y\", \"ppscore\"]).pivot(columns=\"x\", index=\"y\", values=\"ppscore\")\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter([\"ppscore\"]).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide the threshold for the heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Predictive power Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
        "                  df_corr_spearman=df_corr_spearman, \n",
        "                  pps_matrix=pps_matrix,\n",
        "                  CorrThreshold=0.4, PPS_Threshold=0.15,\n",
        "                  figsize=(10,10), font_annot=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Values Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will conduct a concise evaluation of missing data, providing a shorter overview than the extensive report generated by pandas profiling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute / len(df) * 100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "        data={\n",
        "            \"RowsWithMissingData\": missing_data_absolute,\n",
        "            \"PercentageOfDataset\": missing_data_percentage,\n",
        "            \"DataType\": df.dtypes\n",
        "        })\n",
        "        .sort_values(by=[\"PercentageOfDataset\"], ascending=False)\n",
        "        .query(\"PercentageOfDataset > 0\")\n",
        "    )\n",
        "\n",
        "    if df_missing_data.empty:\n",
        "        print(\"There are no variables with missing data\")\n",
        "    else:\n",
        "        return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here\"s a concise summary of the strategies for handling missing data for each variable in order of appearance:\n",
        "\n",
        "- **EnclosedPorch** - (90.68% missing data): <br>\n",
        "This variable will be dropped due to a high percentage of missing data.\n",
        "\n",
        "- **WoodDeckSF** - (89.38% missing data): <br>\n",
        "Similarly, this variable will be dropped due to the extensive missing data.\n",
        "\n",
        "- **LotFrontage** - (17.74% missing data):\n",
        "    - Exhibits a moderate correlation with Sale Price but lacks predictive power.\n",
        "    - Imputation with the median (69) is considered, as 0 is not a logical fill for property street frontage. The mean is 70, showing a right skew.\n",
        "\n",
        "- **GarageFinish** - (11.10% missing data):\n",
        "    - This categorical variable includes values: Unfinished (unf), Rough Finished (rfn), Finished (fin), and None.\n",
        "    - Missing values will be checked against garage area; \"None\" will be imputed if no garage area is present, otherwise most likely \"Unfinished\".\n",
        "\n",
        "- **BsmtFinType1** - (7.81% missing data):\n",
        "    - Similar to the approach for GarageFinish, inspect properties with missing values to determine if there is any basement area, and assign \"None\" if applicable.\n",
        "    - Additional analysis will be necessary to address this variable further.\n",
        "\n",
        "- **BedroomAbvGr** - (6.78% missing data):\n",
        "    - Only 6 entries, representing 0.4% of the dataset, have a value of 0 for bedrooms above grade. This suggests that the missing data is unlikely to be attributable to the absence of bedrooms above grade.\n",
        "    - Median and mean values are 3 and 2.9 respectively.\n",
        "\n",
        "- **2ndFlrSF** - (5.89% missing data):\n",
        "    - Zero can be assigned to properties with no second floor, as 53.5% of the dataset already has a value of 0 for this variable.\n",
        "\n",
        "- **GarageYrBlt** - (5.55% missing data):\n",
        "    - Highly correlated with the year built, suggesting it could often be the same as the construction year.\n",
        "    - Missing values might be substituted with the year built where logical.\n",
        "    - If both GarageFinish and GarageArea have a value of \"None\" and \"0\" respectively, it is likely that the property does not have a garage.\n",
        "\n",
        "- **MasVnrArea** - (0.55% missing data):\n",
        "    - The absence of values for MasVnrArea could indicate that there is no masonry veneer, especially since 59% of the values are 0, which is also the median value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a Duplicate Dataset for Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we\"ll create a copy of the dataset and apply the cleaning procedures to this copy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_cleaned = df.copy()\n",
        "df_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section, we will examine and address missing data by analyzing its relationship with other relevant variables and making appropriate adjustments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **EnclosedPorch** and **WoodDeckSF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As mentioned in the initial analysis, a significant amount of data for these variables is missing (90.68% and 89.38% respectively). Therefore we will drop these variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Drop specified columns from the cleaned dataframe\n",
        "df_cleaned = df_cleaned.drop(columns=[\"EnclosedPorch\", \"WoodDeckSF\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We verify that the specified variables have been successfully removed from the dataframe with the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Print all variables with missing data to verify that the specified variables have been successfully removed\n",
        "EvaluateMissingData(df_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As illustrated, the variables **EnclosedPorch** and **WoodDeckSF** no longer appear in the list of variables with missing data, confirming their successful removal from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **LotFrontage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LotFrontage** measures the linear feet of street frontage connected to a property, and logically, this value cannot be zero. A review of the dataset confirms there are no zero values.\n",
        "\n",
        "The following code block is designed to identify and count the rows where **LotFrontage** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_lotfrontage = df_cleaned[df_cleaned[\"LotFrontage\"].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_lotfrontage)}\")\n",
        "missing_lotfrontage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The right-skewed distribution shown in the histogram from the Pandas Profile Report suggests that using the median for imputation is more appropriate than the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculate the median value of \"LotFrontage\" from the cleaned data\n",
        "median_lot_frontage = df_cleaned[\"LotFrontage\"].median()\n",
        "print(f\"Median value is: {median_lot_frontage}\")\n",
        "\n",
        "# Fill missing values in \"LotFrontage\" with the median value\n",
        "df_cleaned[\"LotFrontage\"].fillna(median_lot_frontage, inplace=True)\n",
        "print(\"Filled the missing data with the median value\")\n",
        "\n",
        "# Verify the changes by checking for any remaining null values in the \"LotFrontage\" column\n",
        "print(f'Variables with missing \"Lot Frontage\" value: {df_cleaned[\"LotFrontage\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **GarageFinish**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**GarageFinish** refers to the interior finish of the garage, categorized by values such as \"Unf\" (Unfinished), \"RFn\" (Rough Finished), \"Fin\" (Finished), and \"None\" (No Garage).\n",
        "\n",
        "The following code block is designed to identify and count the rows where **GarageFinish** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "missing_garage_finish = df_cleaned[df_cleaned[\"GarageFinish\"].isnull()]\n",
        "print(f\"Amount of rows with missing data: {len(missing_garage_finish)}\")\n",
        "missing_garage_finish[[\"GarageFinish\", \"GarageYrBlt\", \"GarageArea\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will initially inspect properties to identify those that lack a garage, indicated by a **GarageArea** of 0. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_no_garage_area = df_cleaned[(df_cleaned[\"GarageFinish\"].isnull()) & (df[\"GarageArea\"] == 0)]\n",
        "print(f\"Amount of rows with missing data: {len(df_no_garage_area)}\")\n",
        "df_no_garage_area[[\"GarageFinish\", \"GarageYrBlt\", \"GarageArea\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For these properties, we will impute the **GarageFinish** attribute as \"None\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Count initial number of properties without a garage (\"GarageArea\" is 0) and missing \"GarageFinish\"\n",
        "initial_count = df_cleaned[(df_cleaned[\"GarageArea\"] == 0) & (df_cleaned[\"GarageFinish\"].isnull())].shape[0]\n",
        "print(f'Initial number of rows with \"GarageFinish\" missing and no \"GarageArea\" value: {initial_count}')\n",
        "\n",
        "# Assign the value \"None\" to \"GarageFinish\" for properties where \"GarageArea\" is 0\n",
        "df_cleaned.loc[(df_cleaned[\"GarageArea\"] == 0) & (df_cleaned[\"GarageFinish\"].isnull()), \"GarageFinish\"] = \"None\"\n",
        "\n",
        "# Count the number of properties that still have missing \"GarageFinish\" after the update\n",
        "remaining_count = df_cleaned[(df_cleaned[\"GarageArea\"] == 0) & (df_cleaned[\"GarageFinish\"].isnull())].shape[0]\n",
        "print(f'Remaining number of rows with \"GarageFinish\" missing and no \"GarageArea\" value after update: {remaining_count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the remaining properties that have a specified **GarageArea** but missing **GarageFinish**, we will impute the value \"Unf\", which is the most frequently occurring category for this variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Display the amount of rows with missing \"GarageFinish\" values\n",
        "print(f'Initial number of rows with \"GarageFinish\" missing: {df_cleaned[\"GarageFinish\"].isnull().sum()}')\n",
        "\n",
        "# Impute missing \"GarageFinish\" values with \"Unf\" (Unfinished)\n",
        "df_cleaned.loc[(df_cleaned[\"GarageFinish\"].isnull()), \"GarageFinish\"] = \"Unf\"\n",
        "\n",
        "# Check and display the number of remaining missing entries in \"GarageFinish\" after imputation\n",
        "print(f'Remaining missing \"GarageFinish\" entries: {df_cleaned[\"GarageFinish\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **BsmtFinType1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BsmtFinType1** refers to the quality of the basement finish, categorized by values such as \"GLQ\" (Good Living Quarters), \"ALQ\" (Average Living Quarters), \"BLQ\" (Below Average Living Quarters), \"Rec\" (Average Recreational Room), \"LwQ\" (Low Quality), \"Unf\" (Unfinished), and \"None\" (No Basement).\n",
        "\n",
        "\n",
        "The following code block is designed to identify and count the rows where **BsmtFinType1** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identifying and counting the  missing entries for the \"BsmtFinType1\" column in the cleaned DataFrame\n",
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned[\"BsmtFinType1\"].isnull()]\n",
        "\n",
        "# Printing the number of rows with missing \"BsmtFinType1\" data\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "\n",
        "# Displaying specific columns of interest from rows with missing \"BsmtFinType1\"\n",
        "missing_bsmtfin_type1[[\"BsmtFinType1\", \"TotalBsmtSF\", \"BsmtUnfSF\", \"BsmtFinSF1\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the missing values for **BsmtFinType1** where **TotalBsmtSF** is zero. Properties with a basement square footage of zero indicate no basement present, which justifies setting **BsmtFinType1** to \"None\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identifying and counting the missing entries for the \"BsmtFinType1\" column in the cleaned DataFrame with a \"TotalBsmtSF\" value of 0\n",
        "df_basement_none = df_cleaned[(df[\"BsmtFinType1\"].isnull()) & (df[\"TotalBsmtSF\"] == 0)]\n",
        "\n",
        "# Printing the number of rows\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_none)}\")\n",
        "df_basement_none[[\"BsmtFinType1\", \"TotalBsmtSF\", \"BsmtUnfSF\", \"BsmtFinSF1\", \"BsmtExposure\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rows above display zero values for finished, unfinished, and total basement area, and also lack **BsmtExposure**. This confirms the absence of a basement, allowing us to confidently impute \"None\" for **BsmtFinType1**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's proceed to impute these values now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Update \"BsmtFinType1\" to \"None\" for rows where there is no basement (\"TotalBsmtSF\" is 0)\n",
        "df_cleaned.loc[(df_cleaned[\"TotalBsmtSF\"] == 0) & (df_cleaned[\"BsmtFinType1\"].isnull()), \"BsmtFinType1\"] = \"None\"\n",
        "\n",
        "# Display the remaining number of rows that still have missing \"BsmtFinType1\" data\n",
        "print(f'Amount of rows left with missing \"BsmtFinType1\" data: {df_cleaned[\"BsmtFinType1\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are 108 rows remaining with missing **BsmtFinType1** data.\n",
        "\n",
        "The values belows indicate that the variable **BsmtUnfSF** has 0 square feet unfinished, and since the **TotalBsmtSF** is greater than 0, it suggests the basement is finished but no category has been assigned.\n",
        "\n",
        "As we cannot deduce if it is a rec room/living quarter and the quality, we should create a new category: \"Finished\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Rows where \"BsmtFinType1' is missing and 'BsmtUnfSF' equals 0\n",
        "df_basement_finished = df_cleaned[(df_cleaned[\"BsmtFinType1\"].isnull()) & (df[\"BsmtUnfSF\"] == 0)]\n",
        "\n",
        "# Printing the count of rows where basement finishing type is missing but there is no unfinished space\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_finished)}\")\n",
        "\n",
        "# Displaying the selected columns for the filtered rows\n",
        "df_basement_finished[[\"BsmtFinType1\", \"TotalBsmtSF\", \"BsmtUnfSF\", \"BsmtFinSF1\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's proceed to impute \"Fin\" value now to these rows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Update \"BsmtFinType1\" to \"Fin\" for rows where there is a value of \"0\" for \"BsmtUnfSF\"\n",
        "df_cleaned.loc[(df_cleaned[\"BsmtFinType1\"].isnull()) & (df[\"BsmtUnfSF\"] == 0), \"BsmtFinType1\"] = \"Fin\"\n",
        "\n",
        "# Display the remaining number of rows that still have missing 'BsmtFinType1' data\n",
        "print(f'Amount of rows left with missing \"BsmtFinType1\" data: {df_cleaned[\"BsmtFinType1\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are still 102 rows missing data for **BsmtFinType1**.\n",
        "\n",
        "In cases where the unfinished basement square footage (**BsmtUnfSF**) is greater than 0, we can reasonably impute these entries as 'Unfinished'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Select rows where \"BsmtFinType1\" is missing and \"BsmtUnfSF\" is greater than 0\n",
        "df_basement_unfinished = df_cleaned[(df_cleaned[\"BsmtFinType1\"].isnull()) & (df[\"BsmtUnfSF\"] > 0)]\n",
        "\n",
        "# Print the number of rows found with these conditions\n",
        "print(f\"Amount of rows with missing data: {len(df_basement_unfinished)}\")\n",
        "\n",
        "# Display the relevant columns for these rows to review the data\n",
        "df_basement_unfinished[[\"BsmtFinType1\", \"TotalBsmtSF\", \"BsmtUnfSF\", \"BsmtFinSF1\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The DataFrame above indicates that all remaining entries with missing data have a **BsmtUnfSF** (unfinished basement square footage) value greater than 0.\n",
        "\n",
        "This suggests that these basements are indeed unfinished. We can confidently impute the category \"Unfinished\" to all these instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Update \"BsmtFinType1\" to \"Unf\" for rows where there is a value greater than \"0\" for \"BsmtUnfSF\"\n",
        "df_cleaned.loc[(df_cleaned[\"BsmtFinType1\"].isnull()) & (df[\"BsmtUnfSF\"] > 0), \"BsmtFinType1\"] = \"Unf\"\n",
        "\n",
        "# Print the count of remaining missing values in \"BsmtFinType1\" to verify all necessary changes were applied\n",
        "print(f'Amount of rows left with missing \"BsmtFinType1\" data: {df_cleaned[\"BsmtFinType1\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now perform a final check to ensure there are no remaining rows with missing data in the **BsmtFinType1** column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identifying and counting the remaining missing entries for the \"BsmtFinType1\" column in the cleaned DataFrame\n",
        "missing_bsmtfin_type1 = df_cleaned[df_cleaned[\"BsmtFinType1\"].isnull()]\n",
        "\n",
        "# Printing the number of remaining rows with missing \"BsmtFinType1\" data\n",
        "print(f\"Amount of rows with missing data: {len(missing_bsmtfin_type1)}\")\n",
        "missing_bsmtfin_type1[[\"BsmtFinType1\", \"TotalBsmtSF\", \"BsmtUnfSF\", \"BsmtFinSF1\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **BedroomAbvGr**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**BedroomAbvGr** refers to the number of bedrooms above the ground level. This numeric variable quantifies the number of bedrooms in a property, excluding any potential basement bedrooms.\n",
        "\n",
        "The following code block is designed to identify and count the rows where **BedroomAbvGr** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identify rows in the cleaned DataFrame where \"BedroomAbvGr\" is missing\n",
        "missing_bedroom_abv_gr = df_cleaned[df_cleaned[\"BedroomAbvGr\"].isnull()]\n",
        "\n",
        "# Output the number of rows where \"BedroomAbvGr\" is missing\n",
        "print(f\"Amount of rows with missing data: {len(missing_bedroom_abv_gr)}\")\n",
        "missing_bedroom_abv_gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As indicated by our initial analysis, only 0.6% of the values for **BedroomAbvGr** are recorded as 0, suggesting that instances of zero bedrooms are rare. \n",
        "\n",
        "Given this distribution, it is reasonable to fill missing values with the median, which is 3, as this represents a typical configuration for properties in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculate the median value of \"BedroomAbvGr\" from the cleaned data\n",
        "median_bedroom_abv_gr = df_cleaned[\"BedroomAbvGr\"].median()\n",
        "\n",
        "# Print the median value used for imputation\n",
        "print(f\"Median number of bedrooms above grade used for imputation: {median_bedroom_abv_gr}\")\n",
        "\n",
        "# Print the amount of missing data in \"BedroomAbvGr\" before imputation\n",
        "print(f'Amount of rows with missing \"BedroomAbvGr\" data before imputation: {df_cleaned[\"BedroomAbvGr\"].isnull().sum()}')\n",
        "\n",
        "# Impute missing values with the calculated median\n",
        "df_cleaned[\"BedroomAbvGr\"].fillna(median_bedroom_abv_gr, inplace=True)\n",
        "\n",
        "# Re-check and print the amount of missing data in \"BedroomAbvGr\" to ensure no missing values remain\n",
        "missing_after_imputation = df_cleaned[\"BedroomAbvGr\"].isnull().sum()\n",
        "print(f'Amount of rows with missing \"BedroomAbvGr\" data after imputation: {df_cleaned[\"BedroomAbvGr\"].isnull().sum()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2ndFlrSF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2ndFlrSF** refers to the square footage of the second floor of the house. This variable quantifies the area of any living space above the first floor.\n",
        "\n",
        "The following code block is designed to identify and count the rows where **2ndFlrSF** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identifying and counting the  missing entries for the \"2ndFlrSF\" column in the cleaned DataFrame\n",
        "missing_2nd_flr_sf = df_cleaned[df_cleaned[\"2ndFlrSF\"].isnull()]\n",
        "\n",
        "# Printing the number of rows with missing \"2ndFlrSF\" data\n",
        "print(f\"Amount of rows with missing data: {len(missing_2nd_flr_sf)}\")\n",
        "\n",
        "# Displaying rows with missing \"2ndFlrSF\"\n",
        "missing_2nd_flr_sf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As indicated in our initial analysis, properties with no second floor can be assigned a value of zero for **2ndFlrSF**, as 53.5% of the dataset already has a value of zero for this variable.\n",
        "\n",
        "Let's proceed to impute zero for the missing values in **2ndFlrSF**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Print the number of missing entries before imputation\n",
        "initial_missing = df_cleaned[\"2ndFlrSF\"].isnull().sum()\n",
        "print(f'Amount of rows with missing \"2ndFlrSF\" data before imputation: {initial_missing}')\n",
        "\n",
        "# Impute 0 for all missing values in \"2ndFlrSF\"\n",
        "df_cleaned[\"2ndFlrSF\"].fillna(0, inplace=True)\n",
        "\n",
        "# Check and print the amount of missing data in \"2ndFlrSF\" after imputation to ensure no missing values remain\n",
        "print(f'Amount of rows with missing \"2ndFlrSF\" data after imputation: {df_cleaned[\"2ndFlrSF\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **GarageYrBlt**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**GarageYrBlt** refers to the year the garage was built.\n",
        "\n",
        "The following code block is designed to identify and count the rows where **GarageYrBlt** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identifying and counting the  missing entries for the \"GarageYrBlt\" column in the cleaned DataFrame\n",
        "missing_garage_yr_built = df_cleaned[df_cleaned[\"GarageYrBlt\"].isnull()]\n",
        "\n",
        "# Printing the number of rows with missing \"GarageYrBlt\" data\n",
        "print(f\"Amount of rows with missing data: {len(missing_garage_yr_built)}\")\n",
        "\n",
        "# Displaying the selected columns for the filtered rows\n",
        "missing_garage_yr_built[[\"GarageYrBlt\", \"GarageFinish\", \"GarageArea\", \"YearBuilt\", \"YearRemodAdd\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will check how many of the missing values in **GarageYrBlt** have a **GarageArea** equal to 0, which would indicate that the missing value is due to the absence of a garage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to identify rows where 'GarageYrBlt' is missing and 'GarageArea' is 0\n",
        "df_garage_year_none = df_cleaned[(df_cleaned[\"GarageYrBlt\"].isnull()) & (df_cleaned[\"GarageArea\"] == 0)]\n",
        "\n",
        "# Print the number of rows that match this condition\n",
        "print(f\"Amount of rows with missing data: {len(df_garage_year_none)}\")\n",
        "\n",
        "# Display the relevant columns for the identified rows\n",
        "df_garage_year_none[[\"GarageYrBlt\", \"GarageFinish\", \"GarageArea\", \"YearBuilt\", \"YearRemodAdd\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All missing values in **GarageYrBlt** correspond to properties without a garage, as indicated by a zero in the GarageArea.\n",
        "\n",
        "The **GarageYrBlt** variable has significant Power Predictive Scores (PPS) of 0.6 with **YearBuilt** and 0.4 with **YearRemodAdd**, strongly suggesting that garages are typically constructed at the same time as the main house or during major renovations. This substantial overlap implies that **GarageYrBlt** does not add unique value beyond what is already conveyed by **YearBuilt** or **YearRemodelAdd**.\n",
        "\n",
        "Considering this redundancy, although we could impute a value of 0 for properties without garages to indicate no garage was built it is not ideal as it would set the Year the garage was built as Year 0. \n",
        "It is more prudent to remove **GarageYrBlt** from the dataset entirely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Drops the specified column from the cleaned dataframe\n",
        "df_cleaned.drop(\"GarageYrBlt\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We verify that the specified variable has been successfully removed from the dataframe with the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "for column in df_cleaned.columns:\n",
        "    print(column)\n",
        "\n",
        "# Print all variables with missing data to verify that the specified variables have been successfully removed\n",
        "EvaluateMissingData(df_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As illustrated, the variable **GarageYrBlt** no longer appears in the list of variables and in the list of variables with missing data, confirming the successful removal from the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **MasVnrArea**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**MasVnrArea** stands for Masonry Veneer Area and measures the square footage of masonry veneer applied to the house.\n",
        "\n",
        "The following code block is designed to identify and count the rows where **MasVnrArea** is missing in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Identifying and counting the  missing entries for the \"MasVnrArea\" column in the cleaned DataFrame\n",
        "missing_mas_vnr_area = df_cleaned[df_cleaned[\"MasVnrArea\"].isnull()]\n",
        "\n",
        "# Printing the number of rows with missing \"MasVnrArea\" data\n",
        "print(f\"Amount of rows with missing data: {len(missing_mas_vnr_area)}\")\n",
        "\n",
        "# Displaying the filtered rows\n",
        "missing_mas_vnr_area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The missing values for the **MasVnrArea** variable will be filled with zero, which is its median value. Imputing zero is meaningful in this context, as it indicates properties that do not have any masonry veneer area."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Print the number of missing entries before imputation\n",
        "initial_missing = df_cleaned[\"MasVnrArea\"].isnull().sum()\n",
        "print(f'Amount of rows with missing \"MasVnrArea\" data before imputation: {initial_missing}')\n",
        "\n",
        "# Impute 0 for all missing values in \"MasVnrArea\"\n",
        "df_cleaned[\"MasVnrArea\"].fillna(0, inplace=True)\n",
        "\n",
        "# Check and print the amount of missing data in \"MasVnrArea\" after imputation to ensure no missing values remain\n",
        "print(f'Amount of rows with missing \"MasVnrArea\" data after imputation: {df_cleaned[\"MasVnrArea\"].isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now use a custom function from Code Institute (CI) to compare the differences between the dataframe before and after cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DataCleaningEffect(df_original,df_cleaned,variables_applied_with_method):\n",
        "\n",
        "  flag_count=1 # Indicate plot number\n",
        "  \n",
        "  # distinguish between numerical and categorical variables\n",
        "  categorical_variables = df_original.select_dtypes(exclude=[\"number\"]).columns \n",
        "\n",
        "  # scan over variables, \n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if categorical plot a barplot\n",
        "  for set_of_variables in [variables_applied_with_method]:\n",
        "    print(\"\\n=====================================================================================\")\n",
        "    print(f\"* Distribution Effect Analysis After Data Cleaning Method in the following variables:\")\n",
        "    print(f\"{set_of_variables} \\n\\n\")\n",
        "  \n",
        "\n",
        "    for var in set_of_variables:\n",
        "      if var in categorical_variables:  # it is categorical variable: barplot\n",
        "        \n",
        "        df1 = pd.DataFrame({\"Type\":\"Original\",\"Value\":df_original[var]})\n",
        "        df2 = pd.DataFrame({\"Type\":\"Cleaned\",\"Value\":df_cleaned[var]})\n",
        "        dfAux = pd.concat([df1, df2], axis=0)\n",
        "        fig , axes = plt.subplots(figsize=(15, 5))\n",
        "        sns.countplot(hue=\"Type\", data=dfAux, x=\"Value\",palette=[\"#432371\",\"#FAAE7B\"])\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.legend() \n",
        "\n",
        "      else: # it is numerical variable: histogram\n",
        "\n",
        "        fig , axes = plt.subplots(figsize=(10, 5))\n",
        "        sns.histplot(data=df_original, x=var, color=\"#432371\", label=\"Original\", kde=True,element=\"step\", ax=axes)\n",
        "        sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label=\"Cleaned\", kde=True,element=\"step\", ax=axes)\n",
        "        axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "        plt.legend() \n",
        "\n",
        "      plt.show()\n",
        "      flag_count+= 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# List of variables that we want to analyze to see the effect of data cleaning\n",
        "variables_to_analyze = [\n",
        "    \"GarageFinish\", \"BsmtFinType1\", \"LotFrontage\", \"BedroomAbvGr\", \"2ndFlrSF\", \"MasVnrArea\"\n",
        "]\n",
        "\n",
        "# \"df_original\" refers to the DataFrame before any cleaning was applied\n",
        "# \"df_cleaned\" refers to the DataFrame after cleaning operations have been performed\n",
        "# \"variables_applied_with_method\" is a list of variable names that we want to compare\n",
        "# This function will display visual comparisons for each variable listed\n",
        "DataCleaningEffect(df_original=df, df_cleaned=df_cleaned, variables_applied_with_method=variables_to_analyze)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we will verify that there are no remaining missing data points in our cleaned dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "EvaluateMissingData(df_cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since there is no more missing data, we can progress to the next step of splitting the cleaned dataset into training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "metadata": {},
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name=\"\")\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
