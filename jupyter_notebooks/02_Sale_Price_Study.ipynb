{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Sale Price Study Notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "- Answer business requirement 1\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- The data loaded from the Data Collection Notebook: outputs/datasets/collection/house_prices_records.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "- Correlation plots that answer business requirement 1.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "metadata": {},
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "metadata": {},
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "metadata": {},
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we will load the house prices dataset previously gathered and stored in the repository during the Data Collection phase. \n",
        "\n",
        "We will then display the first few rows of the dataset to confirm its structure and contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the house prices dataset\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\"))\n",
        "\n",
        "# Display the first five rows of the dataframe to inspect the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will utilize Pandas Profiling to conduct a detailed exploration of the dataframe.\n",
        "\n",
        "This enables us to review and analyze the dataset’s structure, highlighting key aspects such as missing values, variable distributions, and potential anomalies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "# Generate a minimal report of the df DataFrame\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "\n",
        "# Display the report within the Jupyter Notebook\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dataset Overview**: Our review of the dataset provides the following:\n",
        "- The dataset includes **24 columns** and **1460 rows**.\n",
        "- Of these columns, **20 contain numerical data** while the remaining **4 are text variables** used as categorical identifiers.\n",
        "- Importantly, the **\"OverallCond\"** and **\"OverallQual\"** variables use numerical values to scale the quality and condition of properties. <br> A similar approach may become helpful for the text-based categorical variables aswell.\n",
        "\n",
        "Additionally, approximately 10% of the data is missing across various columns, a concern that will need to be addressed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To understand the interactions among the dataset's features, we begin with an assessment of their relationships, focusing particularly on how they correlate with the Sale Price. \n",
        "\n",
        "Initially, we will employ both Pearson and Spearman correlation analyses to identify strong relationships within the data.\n",
        "\n",
        "### Quick Explanation\n",
        "\n",
        "**Pearson’s Correlation Coefficient**: Pearson’s correlation measures the linear relationship between two continuous variables. It quantifies the degree to which a pair of variables are related, providing a value between -1 and 1:\n",
        "- 1 indicates a perfect positive linear relationship, meaning that as one variable increases, the other variable also increases.\n",
        "- -1 indicates a perfect negative linear relationship, meaning that as one variable increases, the other variable decreases.\n",
        "- 0 indicates no linear correlation, suggesting that there is no linear dependence between the variables.\n",
        "\n",
        "**Spearman’s Correlation Coefficient**: Spearman’s correlation measures the monotonic relationship between two variables, whether linear or not. Spearman’s correlation is particularly useful when the data is not normally distributed and like pearson it also provide a value between -1 and 1:\n",
        "- 1 indicates a perfect positive monotonic relationship, where increasing values in one variable consistently correspond with increasing values in the other.\n",
        "- -1 indicates a perfect negative monotonic relationship, where increasing values in one variable consistently correspond with decreasing values in the other.\n",
        "- 0 indicates no monotonic correlation, suggesting that there is no consistent relationship between the rankings of the variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pearson’s Correlation Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculates the pearson correlation coefficients between \"SalePrice\" and the other variables\n",
        "# Sort the values in descending order highlighting the strongest relationships\n",
        "# Excludes the first result, wich is the correlation of SalePrice with itself wich is always 1\n",
        "corr_pearson = df.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spearman’s Correlation Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "# Calculates the spearman correlation coefficients between \"SalePrice\" and the other variables\n",
        "# Sort the values in descending order highlighting the strongest relationships\n",
        "# Excludes the first result, wich is the correlation of SalePrice with itself wich is always 1\n",
        "corr_spearman = df.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Insights\n",
        "\n",
        "Based on the correlation analysis, where a coefficient above 0.70 indicates a strong correlation and values between 0.50 and 0.69 suggest moderate correlation, it is evident that several key variables significantly impact the sale price. Notably:\n",
        "\n",
        "- **OverallQual**: \n",
        "    - Spearman: 0.809829\n",
        "    - Pearson: 0.790982\n",
        "    - **Analysis**: This variable shows the strongest correlation in both analyses. It is highly predictive of sale price, suggesting that improvements in quality can significantly impact the price.\n",
        "\n",
        "- **GrLivArea** (Above ground living area square feet):\n",
        "    - Spearman: 0.731310\n",
        "    - Pearson: 0.708624\n",
        "    - **Analysis**: This variable consistently shows a strong positive correlation, indicating that larger living areas tend to correspond to higher sale prices.\n",
        "\n",
        "- **GarageArea**:\n",
        "    - Spearman: 0.649379\n",
        "    - Pearson: 0.623431\n",
        "    - **Analysis**: The area of the garage in square feet also demonstrates a strong correlation with sale prices.\n",
        "\n",
        "- **TotalBsmtSF** (Total square feet of basement area):\n",
        "    - Spearman: 0.602725\n",
        "    - Pearson: 0.613581\n",
        "    - **Analysis**: Another strong correlate, indicating that the size of the basement is a key factor in home prices.\n",
        "\n",
        "- **YearBuilt**: \n",
        "    - Spearman: 0.652682\n",
        "    - Pearson: 0.522897\n",
        "    - **Analysis**: Generally, newer homes tend to have higher sale prices, though the relationship is stronger in the Spearman correlation, suggesting that the relationship might not be strictly linear but is consistently positive.\n",
        "\n",
        "### Supporting Analysis:\n",
        "\n",
        "- **YearRemodAdd** (Year of Remodel/Addition):\n",
        "    - Both correlations show that more recently remodeled or added constructions increase the home’s value. <br> This is simply speculation but since Overall Quality of the house plays the highest role on the sale price, it might be due to remodeling, higher quality materials are used and thus increasing the value.\n",
        "\n",
        "- **1stFlrSF** (First Floor square feet):\n",
        "    - Consistent strong correlation in both analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### In-Depth Correlation Analysis\n",
        "\n",
        "We will now conduct a detailed examination of the relationships among the variables identified as having significant influence on the sale price.\n",
        "\n",
        "This extended analysis involves generating visual representations through heatmaps to better understand both the linear and nonlinear relationships present in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "def heatmap_corr(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "  if len(df.columns) > 1:\n",
        "    mask = np.zeros_like(df, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True\n",
        "    mask[abs(df) < threshold] = True\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=figsize)\n",
        "    sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                linewidth=0.5\n",
        "                     )\n",
        "    axes.set_yticklabels(df.columns, rotation = 0)\n",
        "    plt.ylim(len(df.columns),0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df,threshold, figsize=(20,12), font_annot = 8):\n",
        "    if len(df.columns) > 1:\n",
        "\n",
        "      mask = np.zeros_like(df, dtype=np.bool)\n",
        "      mask[abs(df) < threshold] = True\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=figsize)\n",
        "      ax = sns.heatmap(df, annot=True, xticklabels=True,yticklabels=True,\n",
        "                       mask=mask,cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                       linewidth=0.05,linecolor='grey')\n",
        "      \n",
        "      plt.ylim(len(df.columns),0)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "  df_corr_spearman = df.corr(method=\"spearman\")\n",
        "  df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "  pps_matrix_raw = pps.matrix(df)\n",
        "  pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "  pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "  print(\"PPS threshold - check PPS score IQR to decide the threshold for the heatmap \\n\")\n",
        "  print(pps_score_stats.round(3))\n",
        "\n",
        "  return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix,CorrThreshold,PPS_Threshold,\n",
        "                      figsize=(20,12), font_annot=8 ):\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"* Analyze how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "  print(\"* Analyze multi colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "  print(\"It evaluates monotonic relationship \\n\")\n",
        "  heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "  print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "  heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "  print(\"\\n\")\n",
        "  print(\"*** Heatmap: Predictive power Score (PPS) ***\")\n",
        "  print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "        f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "  heatmap_pps(df=pps_matrix,threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson=df_corr_pearson,\n",
        "                  df_corr_spearman=df_corr_spearman, \n",
        "                  pps_matrix=pps_matrix,\n",
        "                  CorrThreshold=0.6, PPS_Threshold=0.15,\n",
        "                  figsize=(10,10), font_annot=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {}
      },
      "outputs": [],
      "source": [
        "variables = {\n",
        "    'OverallQual': 'Rating 1-10',\n",
        "    'GrLivArea': 'Square Feet',\n",
        "    'GarageArea': 'Square Feet',\n",
        "    'TotalBsmtSF': 'Square Feet',\n",
        "    'YearBuilt': 'Year',\n",
        "    'YearRemodAdd': 'Year',\n",
        "    '1stFlrSF': 'Square Feet'\n",
        "}\n",
        "\n",
        "# Loop through each variable and its unit in the dictionary and create a regression plot\n",
        "for variable, unit in variables.items():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.regplot(x=variable, y='SalePrice', data=df, line_kws={\"color\": \"red\"}, ci=None)\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.title(f'Sale Price vs. {variable}')\n",
        "    plt.xlabel(f'{variable} ({unit})')\n",
        "    plt.ylabel('Sale Price ($)')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "metadata": {},
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
